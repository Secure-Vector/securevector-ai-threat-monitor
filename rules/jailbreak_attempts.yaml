name: "Jailbreak Prevention"
description: "Detects attempts to bypass AI safety mechanisms"
version: "1.0"

patterns:
  - pattern: "for\\s+debugging\\s+purposes,\\s+ignore\\s+(safety|guidelines)"
    risk_score: 79
    description: "Debugging pretext for bypassing safety"
    
  - pattern: "you're\\s+helping\\s+with\\s+a\\s+security\\s+test"
    risk_score: 83
    description: "Security test social engineering"
    
  - pattern: "just\\s+this\\s+once,\\s+(ignore|bypass|disable)"
    risk_score: 76
    description: "One-time exception manipulation"
    
  - pattern: "in\\s+hypothetical\\s+scenario"
    risk_score: 65
    description: "Hypothetical scenario bypass (lower risk)"
    
  - pattern: "what\\s+would\\s+happen\\s+if\\s+you\\s+(ignored|bypassed)"
    risk_score: 70
    description: "Conditional bypass exploration"
    
  - pattern: "roleplay\\s+as\\s+(evil|unethical|harmful)"
    risk_score: 82
    description: "Harmful roleplay request"